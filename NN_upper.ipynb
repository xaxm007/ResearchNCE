{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_323885/870596463.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ph_data['pH'] = ph\n",
      "/tmp/ipykernel_323885/870596463.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ph_data['pH'] = ph\n",
      "/tmp/ipykernel_323885/870596463.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ph_data['pH'] = ph\n",
      "/tmp/ipykernel_323885/870596463.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ph_data['pH'] = ph\n",
      "/home/sheesh/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 664us/step - loss: 15.0312 - val_loss: 1.4499\n",
      "Epoch 2/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 614us/step - loss: 2.6276 - val_loss: 1.3646\n",
      "Epoch 3/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 624us/step - loss: 2.2625 - val_loss: 1.4048\n",
      "Epoch 4/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 626us/step - loss: 2.0449 - val_loss: 1.4407\n",
      "Epoch 5/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 646us/step - loss: 1.8669 - val_loss: 1.3886\n",
      "Epoch 6/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 616us/step - loss: 1.7498 - val_loss: 1.3935\n",
      "Epoch 7/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 622us/step - loss: 1.6610 - val_loss: 1.4345\n",
      "Epoch 8/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 612us/step - loss: 1.5507 - val_loss: 1.2960\n",
      "Epoch 9/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 622us/step - loss: 1.4852 - val_loss: 1.2963\n",
      "Epoch 10/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 649us/step - loss: 1.3940 - val_loss: 1.2373\n",
      "Epoch 11/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 619us/step - loss: 1.3628 - val_loss: 1.1621\n",
      "Epoch 12/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 643us/step - loss: 1.2813 - val_loss: 1.1116\n",
      "Epoch 13/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 644us/step - loss: 1.2060 - val_loss: 1.0280\n",
      "Epoch 14/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 626us/step - loss: 1.1565 - val_loss: 0.9687\n",
      "Epoch 15/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 648us/step - loss: 1.1003 - val_loss: 0.9804\n",
      "Epoch 16/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 622us/step - loss: 1.0787 - val_loss: 0.9175\n",
      "Epoch 17/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653us/step - loss: 1.0197 - val_loss: 0.9285\n",
      "Epoch 18/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 637us/step - loss: 1.0069 - val_loss: 0.8599\n",
      "Epoch 19/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 663us/step - loss: 0.9775 - val_loss: 0.8466\n",
      "Epoch 20/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 643us/step - loss: 0.9633 - val_loss: 0.8575\n",
      "Epoch 21/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 655us/step - loss: 0.9529 - val_loss: 0.8270\n",
      "Epoch 22/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 640us/step - loss: 0.9255 - val_loss: 0.8261\n",
      "Epoch 23/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 634us/step - loss: 0.9029 - val_loss: 0.8482\n",
      "Epoch 24/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 654us/step - loss: 0.8992 - val_loss: 0.7938\n",
      "Epoch 25/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 663us/step - loss: 0.8841 - val_loss: 0.8081\n",
      "Epoch 26/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 639us/step - loss: 0.8627 - val_loss: 0.7871\n",
      "Epoch 27/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 641us/step - loss: 0.8646 - val_loss: 0.7938\n",
      "Epoch 28/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 634us/step - loss: 0.8473 - val_loss: 0.7926\n",
      "Epoch 29/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 632us/step - loss: 0.8378 - val_loss: 0.7622\n",
      "Epoch 30/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 624us/step - loss: 0.8377 - val_loss: 0.7643\n",
      "Epoch 31/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 645us/step - loss: 0.8333 - val_loss: 0.7621\n",
      "Epoch 32/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 677us/step - loss: 0.8374 - val_loss: 0.7531\n",
      "Epoch 33/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 646us/step - loss: 0.8125 - val_loss: 0.7421\n",
      "Epoch 34/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 643us/step - loss: 0.8041 - val_loss: 0.7456\n",
      "Epoch 35/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 650us/step - loss: 0.8152 - val_loss: 0.7523\n",
      "Epoch 36/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 661us/step - loss: 0.7977 - val_loss: 0.7303\n",
      "Epoch 37/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 623us/step - loss: 0.7927 - val_loss: 0.7303\n",
      "Epoch 38/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 635us/step - loss: 0.7773 - val_loss: 0.7209\n",
      "Epoch 39/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 641us/step - loss: 0.7749 - val_loss: 0.7264\n",
      "Epoch 40/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 643us/step - loss: 0.7842 - val_loss: 0.7110\n",
      "Epoch 41/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 645us/step - loss: 0.7591 - val_loss: 0.7103\n",
      "Epoch 42/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 657us/step - loss: 0.7660 - val_loss: 0.7298\n",
      "Epoch 43/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 660us/step - loss: 0.7560 - val_loss: 0.7038\n",
      "Epoch 44/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 642us/step - loss: 0.7585 - val_loss: 0.6977\n",
      "Epoch 45/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 636us/step - loss: 0.7566 - val_loss: 0.6892\n",
      "Epoch 46/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653us/step - loss: 0.7466 - val_loss: 0.6928\n",
      "Epoch 47/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 648us/step - loss: 0.7440 - val_loss: 0.6871\n",
      "Epoch 48/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 666us/step - loss: 0.7330 - val_loss: 0.6794\n",
      "Epoch 49/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 647us/step - loss: 0.7384 - val_loss: 0.6786\n",
      "Epoch 50/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 645us/step - loss: 0.7283 - val_loss: 0.6769\n",
      "Epoch 51/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 638us/step - loss: 0.7273 - val_loss: 0.6830\n",
      "Epoch 52/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 660us/step - loss: 0.7289 - val_loss: 0.6865\n",
      "Epoch 53/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 639us/step - loss: 0.7182 - val_loss: 0.6671\n",
      "Epoch 54/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 661us/step - loss: 0.7255 - val_loss: 0.6672\n",
      "Epoch 55/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653us/step - loss: 0.7186 - val_loss: 0.6684\n",
      "Epoch 56/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 629us/step - loss: 0.7232 - val_loss: 0.6625\n",
      "Epoch 57/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 649us/step - loss: 0.7191 - val_loss: 0.6585\n",
      "Epoch 58/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 637us/step - loss: 0.7069 - val_loss: 0.6627\n",
      "Epoch 59/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 676us/step - loss: 0.7086 - val_loss: 0.6518\n",
      "Epoch 60/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 642us/step - loss: 0.7019 - val_loss: 0.6615\n",
      "Epoch 61/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 613us/step - loss: 0.7044 - val_loss: 0.6573\n",
      "Epoch 62/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 633us/step - loss: 0.6930 - val_loss: 0.6528\n",
      "Epoch 63/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 631us/step - loss: 0.6973 - val_loss: 0.6512\n",
      "Epoch 64/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 634us/step - loss: 0.6960 - val_loss: 0.6636\n",
      "Epoch 65/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 641us/step - loss: 0.6999 - val_loss: 0.6457\n",
      "Epoch 66/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 652us/step - loss: 0.6944 - val_loss: 0.6507\n",
      "Epoch 67/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.6969 - val_loss: 0.6558\n",
      "Epoch 68/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 634us/step - loss: 0.7022 - val_loss: 0.6656\n",
      "Epoch 69/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 666us/step - loss: 0.6967 - val_loss: 0.6389\n",
      "Epoch 70/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 652us/step - loss: 0.6861 - val_loss: 0.6654\n",
      "Epoch 71/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 655us/step - loss: 0.6930 - val_loss: 0.6464\n",
      "Epoch 72/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 650us/step - loss: 0.6933 - val_loss: 0.6459\n",
      "Epoch 73/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 661us/step - loss: 0.6852 - val_loss: 0.6377\n",
      "Epoch 74/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 666us/step - loss: 0.6834 - val_loss: 0.6402\n",
      "Epoch 75/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 642us/step - loss: 0.6835 - val_loss: 0.6423\n",
      "Epoch 76/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671us/step - loss: 0.6855 - val_loss: 0.6551\n",
      "Epoch 77/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 635us/step - loss: 0.6877 - val_loss: 0.6360\n",
      "Epoch 78/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.6809 - val_loss: 0.6306\n",
      "Epoch 79/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 636us/step - loss: 0.6826 - val_loss: 0.6476\n",
      "Epoch 80/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 648us/step - loss: 0.6698 - val_loss: 0.6407\n",
      "Epoch 81/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 639us/step - loss: 0.6821 - val_loss: 0.6466\n",
      "Epoch 82/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 662us/step - loss: 0.6842 - val_loss: 0.6329\n",
      "Epoch 83/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653us/step - loss: 0.6921 - val_loss: 0.6326\n",
      "Epoch 84/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 644us/step - loss: 0.6900 - val_loss: 0.6383\n",
      "Epoch 85/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 670us/step - loss: 0.6787 - val_loss: 0.6789\n",
      "Epoch 86/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.6805 - val_loss: 0.6538\n",
      "Epoch 87/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step - loss: 0.6822 - val_loss: 0.6360\n",
      "Epoch 88/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 662us/step - loss: 0.6836 - val_loss: 0.6317\n",
      "Epoch 89/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 665us/step - loss: 0.6773 - val_loss: 0.6318\n",
      "Epoch 90/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 657us/step - loss: 0.6819 - val_loss: 0.6428\n",
      "Epoch 91/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 645us/step - loss: 0.6865 - val_loss: 0.6275\n",
      "Epoch 92/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 680us/step - loss: 0.6786 - val_loss: 0.6535\n",
      "Epoch 93/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.6770 - val_loss: 0.6482\n",
      "Epoch 94/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 654us/step - loss: 0.6774 - val_loss: 0.6447\n",
      "Epoch 95/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 643us/step - loss: 0.6813 - val_loss: 0.6285\n",
      "Epoch 96/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 676us/step - loss: 0.6715 - val_loss: 0.6420\n",
      "Epoch 97/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 650us/step - loss: 0.6728 - val_loss: 0.6392\n",
      "Epoch 98/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 658us/step - loss: 0.6775 - val_loss: 0.6373\n",
      "Epoch 99/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 687us/step - loss: 0.6801 - val_loss: 0.6368\n",
      "Epoch 100/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 676us/step - loss: 0.6699 - val_loss: 0.6350\n",
      "Epoch 101/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.6833 - val_loss: 0.6326\n",
      "Epoch 102/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 629us/step - loss: 0.6649 - val_loss: 0.6256\n",
      "Epoch 103/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 656us/step - loss: 0.6721 - val_loss: 0.6324\n",
      "Epoch 104/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 646us/step - loss: 0.6683 - val_loss: 0.6393\n",
      "Epoch 105/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 644us/step - loss: 0.6754 - val_loss: 0.6283\n",
      "Epoch 106/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 632us/step - loss: 0.6717 - val_loss: 0.6189\n",
      "Epoch 107/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 643us/step - loss: 0.6723 - val_loss: 0.6275\n",
      "Epoch 108/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 674us/step - loss: 0.6759 - val_loss: 0.6228\n",
      "Epoch 109/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 693us/step - loss: 0.6802 - val_loss: 0.6268\n",
      "Epoch 110/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 646us/step - loss: 0.6670 - val_loss: 0.6346\n",
      "Epoch 111/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 670us/step - loss: 0.6706 - val_loss: 0.6288\n",
      "Epoch 112/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 685us/step - loss: 0.6672 - val_loss: 0.6337\n",
      "Epoch 113/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653us/step - loss: 0.6742 - val_loss: 0.6231\n",
      "Epoch 114/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 646us/step - loss: 0.6659 - val_loss: 0.6339\n",
      "Epoch 115/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 640us/step - loss: 0.6798 - val_loss: 0.6209\n",
      "Epoch 116/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 686us/step - loss: 0.6725 - val_loss: 0.6361\n",
      "Epoch 117/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.6678 - val_loss: 0.6509\n",
      "Epoch 118/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 646us/step - loss: 0.6712 - val_loss: 0.6390\n",
      "Epoch 119/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 651us/step - loss: 0.6748 - val_loss: 0.6304\n",
      "Epoch 120/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.6715 - val_loss: 0.6256\n",
      "Epoch 121/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 631us/step - loss: 0.6689 - val_loss: 0.6339\n",
      "Epoch 122/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 629us/step - loss: 0.6668 - val_loss: 0.6176\n",
      "Epoch 123/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 654us/step - loss: 0.6697 - val_loss: 0.6284\n",
      "Epoch 124/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 669us/step - loss: 0.6750 - val_loss: 0.6226\n",
      "Epoch 125/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 648us/step - loss: 0.6679 - val_loss: 0.6270\n",
      "Epoch 126/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 660us/step - loss: 0.6723 - val_loss: 0.6181\n",
      "Epoch 127/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 628us/step - loss: 0.6694 - val_loss: 0.6239\n",
      "Epoch 128/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 636us/step - loss: 0.6557 - val_loss: 0.6370\n",
      "Epoch 129/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 649us/step - loss: 0.6724 - val_loss: 0.6174\n",
      "Epoch 130/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 647us/step - loss: 0.6607 - val_loss: 0.6324\n",
      "Epoch 131/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 648us/step - loss: 0.6633 - val_loss: 0.6415\n",
      "Epoch 132/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 645us/step - loss: 0.6692 - val_loss: 0.6307\n",
      "Epoch 133/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 663us/step - loss: 0.6647 - val_loss: 0.6252\n",
      "Epoch 134/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 664us/step - loss: 0.6679 - val_loss: 0.6253\n",
      "Epoch 135/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 661us/step - loss: 0.6632 - val_loss: 0.6336\n",
      "Epoch 136/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 640us/step - loss: 0.6650 - val_loss: 0.6213\n",
      "Epoch 137/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671us/step - loss: 0.6654 - val_loss: 0.6227\n",
      "Epoch 138/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 650us/step - loss: 0.6673 - val_loss: 0.6237\n",
      "Epoch 139/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 642us/step - loss: 0.6638 - val_loss: 0.6249\n",
      "Epoch 140/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 630us/step - loss: 0.6659 - val_loss: 0.6224\n",
      "Epoch 141/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683us/step - loss: 0.6621 - val_loss: 0.6172\n",
      "Epoch 142/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653us/step - loss: 0.6789 - val_loss: 0.6230\n",
      "Epoch 143/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 660us/step - loss: 0.6603 - val_loss: 0.6196\n",
      "Epoch 144/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 643us/step - loss: 0.6635 - val_loss: 0.6300\n",
      "Epoch 145/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653us/step - loss: 0.6593 - val_loss: 0.6151\n",
      "Epoch 146/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 723us/step - loss: 0.6454 - val_loss: 0.6253\n",
      "Epoch 147/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 654us/step - loss: 0.6549 - val_loss: 0.6235\n",
      "Epoch 148/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 748us/step - loss: 0.6759 - val_loss: 0.6266\n",
      "Epoch 149/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 712us/step - loss: 0.6584 - val_loss: 0.6198\n",
      "Epoch 150/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 713us/step - loss: 0.6624 - val_loss: 0.6389\n",
      "Epoch 151/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 780us/step - loss: 0.6642 - val_loss: 0.6308\n",
      "Epoch 152/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 696us/step - loss: 0.6615 - val_loss: 0.6152\n",
      "Epoch 153/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 680us/step - loss: 0.6645 - val_loss: 0.6160\n",
      "Epoch 154/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 672us/step - loss: 0.6629 - val_loss: 0.6289\n",
      "Epoch 155/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 658us/step - loss: 0.6617 - val_loss: 0.6493\n",
      "Epoch 156/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 698us/step - loss: 0.6560 - val_loss: 0.6411\n",
      "Epoch 157/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 652us/step - loss: 0.6590 - val_loss: 0.6307\n",
      "Epoch 158/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.6687 - val_loss: 0.6126\n",
      "Epoch 159/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 669us/step - loss: 0.6548 - val_loss: 0.6253\n",
      "Epoch 160/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 670us/step - loss: 0.6631 - val_loss: 0.6370\n",
      "Epoch 161/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 670us/step - loss: 0.6616 - val_loss: 0.6185\n",
      "Epoch 162/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 689us/step - loss: 0.6627 - val_loss: 0.6242\n",
      "Epoch 163/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 654us/step - loss: 0.6662 - val_loss: 0.6193\n",
      "Epoch 164/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 692us/step - loss: 0.6455 - val_loss: 0.6269\n",
      "Epoch 165/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 637us/step - loss: 0.6543 - val_loss: 0.6173\n",
      "Epoch 166/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 669us/step - loss: 0.6610 - val_loss: 0.6718\n",
      "Epoch 167/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 682us/step - loss: 0.6635 - val_loss: 0.6341\n",
      "Epoch 168/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653us/step - loss: 0.6511 - val_loss: 0.6196\n",
      "Epoch 169/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 652us/step - loss: 0.6600 - val_loss: 0.6334\n",
      "Epoch 170/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 665us/step - loss: 0.6537 - val_loss: 0.6214\n",
      "Epoch 171/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 654us/step - loss: 0.6505 - val_loss: 0.6177\n",
      "Epoch 172/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 685us/step - loss: 0.6497 - val_loss: 0.6150\n",
      "Epoch 173/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 670us/step - loss: 0.6601 - val_loss: 0.6197\n",
      "Epoch 174/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 654us/step - loss: 0.6660 - val_loss: 0.6159\n",
      "Epoch 175/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 705us/step - loss: 0.6595 - val_loss: 0.6172\n",
      "Epoch 176/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 663us/step - loss: 0.6738 - val_loss: 0.6150\n",
      "Epoch 177/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 681us/step - loss: 0.6555 - val_loss: 0.6249\n",
      "Epoch 178/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 637us/step - loss: 0.6631 - val_loss: 0.6143\n",
      "Epoch 179/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 657us/step - loss: 0.6519 - val_loss: 0.6130\n",
      "Epoch 180/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 654us/step - loss: 0.6617 - val_loss: 0.6288\n",
      "Epoch 181/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 679us/step - loss: 0.6536 - val_loss: 0.6129\n",
      "Epoch 182/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 675us/step - loss: 0.6603 - val_loss: 0.6188\n",
      "Epoch 183/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 681us/step - loss: 0.6529 - val_loss: 0.6208\n",
      "Epoch 184/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 691us/step - loss: 0.6591 - val_loss: 0.6133\n",
      "Epoch 185/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 641us/step - loss: 0.6405 - val_loss: 0.6171\n",
      "Epoch 186/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 622us/step - loss: 0.6540 - val_loss: 0.6207\n",
      "Epoch 187/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 631us/step - loss: 0.6625 - val_loss: 0.6181\n",
      "Epoch 188/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 608us/step - loss: 0.6486 - val_loss: 0.6297\n",
      "Epoch 189/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 604us/step - loss: 0.6589 - val_loss: 0.6114\n",
      "Epoch 190/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 623us/step - loss: 0.6529 - val_loss: 0.6142\n",
      "Epoch 191/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 619us/step - loss: 0.6545 - val_loss: 0.6100\n",
      "Epoch 192/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 613us/step - loss: 0.6493 - val_loss: 0.6105\n",
      "Epoch 193/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 627us/step - loss: 0.6557 - val_loss: 0.6487\n",
      "Epoch 194/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 619us/step - loss: 0.6485 - val_loss: 0.6140\n",
      "Epoch 195/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671us/step - loss: 0.6592 - val_loss: 0.6374\n",
      "Epoch 196/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 673us/step - loss: 0.6564 - val_loss: 0.6111\n",
      "Epoch 197/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 676us/step - loss: 0.6435 - val_loss: 0.6176\n",
      "Epoch 198/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 666us/step - loss: 0.6571 - val_loss: 0.6142\n",
      "Epoch 199/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 700us/step - loss: 0.6537 - val_loss: 0.6236\n",
      "Epoch 200/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 718us/step - loss: 0.6453 - val_loss: 0.6239\n",
      "Epoch 201/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 689us/step - loss: 0.6443 - val_loss: 0.6272\n",
      "Epoch 202/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 687us/step - loss: 0.6587 - val_loss: 0.6247\n",
      "Epoch 203/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 703us/step - loss: 0.6630 - val_loss: 0.6140\n",
      "Epoch 204/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 681us/step - loss: 0.6581 - val_loss: 0.6272\n",
      "Epoch 205/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 677us/step - loss: 0.6627 - val_loss: 0.6408\n",
      "Epoch 206/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 694us/step - loss: 0.6500 - val_loss: 0.6126\n",
      "Epoch 207/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 679us/step - loss: 0.6648 - val_loss: 0.6147\n",
      "Epoch 208/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 719us/step - loss: 0.6589 - val_loss: 0.6316\n",
      "Epoch 209/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 698us/step - loss: 0.6462 - val_loss: 0.6368\n",
      "Epoch 210/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671us/step - loss: 0.6568 - val_loss: 0.6170\n",
      "Epoch 211/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683us/step - loss: 0.6438 - val_loss: 0.6096\n",
      "Epoch 212/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 680us/step - loss: 0.6573 - val_loss: 0.6136\n",
      "Epoch 213/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 709us/step - loss: 0.6512 - val_loss: 0.6146\n",
      "Epoch 214/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 688us/step - loss: 0.6478 - val_loss: 0.6148\n",
      "Epoch 215/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 673us/step - loss: 0.6464 - val_loss: 0.6164\n",
      "Epoch 216/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683us/step - loss: 0.6499 - val_loss: 0.6208\n",
      "Epoch 217/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 703us/step - loss: 0.6507 - val_loss: 0.6134\n",
      "Epoch 218/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 703us/step - loss: 0.6513 - val_loss: 0.6177\n",
      "Epoch 219/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 676us/step - loss: 0.6471 - val_loss: 0.6136\n",
      "Epoch 220/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 672us/step - loss: 0.6449 - val_loss: 0.6111\n",
      "Epoch 221/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step - loss: 0.6456 - val_loss: 0.6258\n",
      "Epoch 222/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 697us/step - loss: 0.6533 - val_loss: 0.6080\n",
      "Epoch 223/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 685us/step - loss: 0.6453 - val_loss: 0.6129\n",
      "Epoch 224/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 701us/step - loss: 0.6514 - val_loss: 0.6053\n",
      "Epoch 225/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 685us/step - loss: 0.6362 - val_loss: 0.6275\n",
      "Epoch 226/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 717us/step - loss: 0.6488 - val_loss: 0.6158\n",
      "Epoch 227/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714us/step - loss: 0.6467 - val_loss: 0.6235\n",
      "Epoch 228/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 684us/step - loss: 0.6561 - val_loss: 0.6128\n",
      "Epoch 229/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 758us/step - loss: 0.6501 - val_loss: 0.6108\n",
      "Epoch 230/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 708us/step - loss: 0.6505 - val_loss: 0.6071\n",
      "Epoch 231/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 664us/step - loss: 0.6422 - val_loss: 0.6181\n",
      "Epoch 232/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 793us/step - loss: 0.6496 - val_loss: 0.6084\n",
      "Epoch 233/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 709us/step - loss: 0.6496 - val_loss: 0.6087\n",
      "Epoch 234/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 709us/step - loss: 0.6556 - val_loss: 0.6136\n",
      "Epoch 235/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 706us/step - loss: 0.6499 - val_loss: 0.6115\n",
      "Epoch 236/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 668us/step - loss: 0.6528 - val_loss: 0.6108\n",
      "Epoch 237/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 696us/step - loss: 0.6423 - val_loss: 0.6138\n",
      "Epoch 238/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 687us/step - loss: 0.6454 - val_loss: 0.6119\n",
      "Epoch 239/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 681us/step - loss: 0.6456 - val_loss: 0.6129\n",
      "Epoch 240/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 719us/step - loss: 0.6521 - val_loss: 0.6110\n",
      "Epoch 241/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 699us/step - loss: 0.6483 - val_loss: 0.6170\n",
      "Epoch 242/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 712us/step - loss: 0.6507 - val_loss: 0.6104\n",
      "Epoch 243/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 667us/step - loss: 0.6509 - val_loss: 0.6116\n",
      "Epoch 244/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 702us/step - loss: 0.6516 - val_loss: 0.6104\n",
      "Epoch 245/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 723us/step - loss: 0.6519 - val_loss: 0.6214\n",
      "Epoch 246/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683us/step - loss: 0.6597 - val_loss: 0.6186\n",
      "Epoch 247/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 675us/step - loss: 0.6488 - val_loss: 0.6144\n",
      "Epoch 248/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 684us/step - loss: 0.6407 - val_loss: 0.6102\n",
      "Epoch 249/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 687us/step - loss: 0.6524 - val_loss: 0.6265\n",
      "Epoch 250/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 696us/step - loss: 0.6490 - val_loss: 0.6104\n",
      "Epoch 251/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683us/step - loss: 0.6554 - val_loss: 0.6101\n",
      "Epoch 252/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 707us/step - loss: 0.6480 - val_loss: 0.6088\n",
      "Epoch 253/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step - loss: 0.6454 - val_loss: 0.6105\n",
      "Epoch 254/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 703us/step - loss: 0.6350 - val_loss: 0.6084\n",
      "Epoch 255/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 709us/step - loss: 0.6405 - val_loss: 0.6076\n",
      "Epoch 256/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 692us/step - loss: 0.6482 - val_loss: 0.6168\n",
      "Epoch 257/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 701us/step - loss: 0.6556 - val_loss: 0.6059\n",
      "Epoch 258/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 686us/step - loss: 0.6502 - val_loss: 0.6127\n",
      "Epoch 259/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 657us/step - loss: 0.6461 - val_loss: 0.6554\n",
      "Epoch 260/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683us/step - loss: 0.6499 - val_loss: 0.6252\n",
      "Epoch 261/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 698us/step - loss: 0.6545 - val_loss: 0.6115\n",
      "Epoch 262/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 670us/step - loss: 0.6496 - val_loss: 0.6080\n",
      "Epoch 263/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 668us/step - loss: 0.6467 - val_loss: 0.6070\n",
      "Epoch 264/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 696us/step - loss: 0.6446 - val_loss: 0.6124\n",
      "Epoch 265/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 664us/step - loss: 0.6454 - val_loss: 0.6329\n",
      "Epoch 266/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 641us/step - loss: 0.6471 - val_loss: 0.6391\n",
      "Epoch 267/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 655us/step - loss: 0.6304 - val_loss: 0.6076\n",
      "Epoch 268/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 645us/step - loss: 0.6543 - val_loss: 0.6059\n",
      "Epoch 269/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 663us/step - loss: 0.6434 - val_loss: 0.6082\n",
      "Epoch 270/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 643us/step - loss: 0.6324 - val_loss: 0.6037\n",
      "Epoch 271/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 673us/step - loss: 0.6379 - val_loss: 0.6172\n",
      "Epoch 272/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 665us/step - loss: 0.6377 - val_loss: 0.6335\n",
      "Epoch 273/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 652us/step - loss: 0.6420 - val_loss: 0.6116\n",
      "Epoch 274/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 669us/step - loss: 0.6443 - val_loss: 0.6170\n",
      "Epoch 275/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 679us/step - loss: 0.6467 - val_loss: 0.6197\n",
      "Epoch 276/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 632us/step - loss: 0.6454 - val_loss: 0.6226\n",
      "Epoch 277/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 700us/step - loss: 0.6453 - val_loss: 0.6111\n",
      "Epoch 278/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653us/step - loss: 0.6474 - val_loss: 0.6218\n",
      "Epoch 279/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 661us/step - loss: 0.6372 - val_loss: 0.6168\n",
      "Epoch 280/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 692us/step - loss: 0.6617 - val_loss: 0.6013\n",
      "Epoch 281/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 698us/step - loss: 0.6514 - val_loss: 0.6079\n",
      "Epoch 282/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 708us/step - loss: 0.6444 - val_loss: 0.6119\n",
      "Epoch 283/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 698us/step - loss: 0.6498 - val_loss: 0.6061\n",
      "Epoch 284/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 677us/step - loss: 0.6496 - val_loss: 0.6354\n",
      "Epoch 285/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 666us/step - loss: 0.6476 - val_loss: 0.6099\n",
      "Epoch 286/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 669us/step - loss: 0.6506 - val_loss: 0.6145\n",
      "Epoch 287/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 672us/step - loss: 0.6437 - val_loss: 0.6089\n",
      "Epoch 288/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 699us/step - loss: 0.6447 - val_loss: 0.6040\n",
      "Epoch 289/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 670us/step - loss: 0.6415 - val_loss: 0.6144\n",
      "Epoch 290/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 662us/step - loss: 0.6404 - val_loss: 0.6055\n",
      "Epoch 291/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 685us/step - loss: 0.6449 - val_loss: 0.6117\n",
      "Epoch 292/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 673us/step - loss: 0.6461 - val_loss: 0.6091\n",
      "Epoch 293/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 684us/step - loss: 0.6410 - val_loss: 0.6121\n",
      "Epoch 294/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 693us/step - loss: 0.6426 - val_loss: 0.6121\n",
      "Epoch 295/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 658us/step - loss: 0.6429 - val_loss: 0.6229\n",
      "Epoch 296/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 660us/step - loss: 0.6457 - val_loss: 0.6074\n",
      "Epoch 297/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 656us/step - loss: 0.6437 - val_loss: 0.6164\n",
      "Epoch 298/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 668us/step - loss: 0.6462 - val_loss: 0.6168\n",
      "Epoch 299/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671us/step - loss: 0.6429 - val_loss: 0.6186\n",
      "Epoch 300/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 668us/step - loss: 0.6369 - val_loss: 0.6083\n",
      "Epoch 301/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 658us/step - loss: 0.6528 - val_loss: 0.6072\n",
      "Epoch 302/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683us/step - loss: 0.6436 - val_loss: 0.6084\n",
      "Epoch 303/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 688us/step - loss: 0.6453 - val_loss: 0.6156\n",
      "Epoch 304/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 664us/step - loss: 0.6482 - val_loss: 0.6045\n",
      "Epoch 305/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 670us/step - loss: 0.6488 - val_loss: 0.6293\n",
      "Epoch 306/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.6513 - val_loss: 0.6162\n",
      "Epoch 307/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 670us/step - loss: 0.6468 - val_loss: 0.6050\n",
      "Epoch 308/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 673us/step - loss: 0.6355 - val_loss: 0.6082\n",
      "Epoch 309/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 694us/step - loss: 0.6411 - val_loss: 0.6147\n",
      "Epoch 310/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 677us/step - loss: 0.6445 - val_loss: 0.6048\n",
      "Epoch 311/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 817us/step - loss: 0.6424 - val_loss: 0.6059\n",
      "Epoch 312/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 727us/step - loss: 0.6400 - val_loss: 0.6094\n",
      "Epoch 313/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 717us/step - loss: 0.6461 - val_loss: 0.6078\n",
      "Epoch 314/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 761us/step - loss: 0.6422 - val_loss: 0.6052\n",
      "Epoch 315/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 727us/step - loss: 0.6449 - val_loss: 0.6087\n",
      "Epoch 316/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 699us/step - loss: 0.6423 - val_loss: 0.6102\n",
      "Epoch 317/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 643us/step - loss: 0.6422 - val_loss: 0.6115\n",
      "Epoch 318/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 638us/step - loss: 0.6360 - val_loss: 0.6099\n",
      "Epoch 319/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 610us/step - loss: 0.6321 - val_loss: 0.6069\n",
      "Epoch 320/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 665us/step - loss: 0.6470 - val_loss: 0.6083\n",
      "Epoch 321/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 652us/step - loss: 0.6437 - val_loss: 0.6088\n",
      "Epoch 322/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 640us/step - loss: 0.6448 - val_loss: 0.6091\n",
      "Epoch 323/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 672us/step - loss: 0.6356 - val_loss: 0.6165\n",
      "Epoch 324/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 681us/step - loss: 0.6508 - val_loss: 0.6068\n",
      "Epoch 325/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 663us/step - loss: 0.6429 - val_loss: 0.6056\n",
      "Epoch 326/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 658us/step - loss: 0.6431 - val_loss: 0.6061\n",
      "Epoch 327/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 662us/step - loss: 0.6453 - val_loss: 0.5996\n",
      "Epoch 328/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 648us/step - loss: 0.6475 - val_loss: 0.6076\n",
      "Epoch 329/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 691us/step - loss: 0.6399 - val_loss: 0.6123\n",
      "Epoch 330/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 638us/step - loss: 0.6404 - val_loss: 0.6145\n",
      "Epoch 331/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 662us/step - loss: 0.6405 - val_loss: 0.6086\n",
      "Epoch 332/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 662us/step - loss: 0.6467 - val_loss: 0.6056\n",
      "Epoch 333/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.6477 - val_loss: 0.6033\n",
      "Epoch 334/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 690us/step - loss: 0.6406 - val_loss: 0.6223\n",
      "Epoch 335/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 667us/step - loss: 0.6405 - val_loss: 0.6186\n",
      "Epoch 336/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 666us/step - loss: 0.6514 - val_loss: 0.6064\n",
      "Epoch 337/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 689us/step - loss: 0.6320 - val_loss: 0.6068\n",
      "Epoch 338/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.6323 - val_loss: 0.6001\n",
      "Epoch 339/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 665us/step - loss: 0.6483 - val_loss: 0.6060\n",
      "Epoch 340/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 658us/step - loss: 0.6406 - val_loss: 0.6162\n",
      "Epoch 341/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 673us/step - loss: 0.6463 - val_loss: 0.6071\n",
      "Epoch 342/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 647us/step - loss: 0.6465 - val_loss: 0.6069\n",
      "Epoch 343/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.6384 - val_loss: 0.6136\n",
      "Epoch 344/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step - loss: 0.6464 - val_loss: 0.6117\n",
      "Epoch 345/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 669us/step - loss: 0.6447 - val_loss: 0.6123\n",
      "Epoch 346/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 689us/step - loss: 0.6389 - val_loss: 0.6126\n",
      "Epoch 347/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 681us/step - loss: 0.6378 - val_loss: 0.6123\n",
      "Epoch 348/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step - loss: 0.6275 - val_loss: 0.6045\n",
      "Epoch 349/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 649us/step - loss: 0.6389 - val_loss: 0.6148\n",
      "Epoch 350/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 665us/step - loss: 0.6529 - val_loss: 0.6345\n",
      "Epoch 351/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 636us/step - loss: 0.6343 - val_loss: 0.6025\n",
      "Epoch 352/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 661us/step - loss: 0.6437 - val_loss: 0.6370\n",
      "Epoch 353/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 667us/step - loss: 0.6414 - val_loss: 0.6108\n",
      "Epoch 354/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step - loss: 0.6392 - val_loss: 0.6092\n",
      "Epoch 355/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.6356 - val_loss: 0.6080\n",
      "Epoch 356/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 708us/step - loss: 0.6395 - val_loss: 0.6218\n",
      "Epoch 357/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 669us/step - loss: 0.6503 - val_loss: 0.6159\n",
      "Epoch 358/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 679us/step - loss: 0.6380 - val_loss: 0.6019\n",
      "Epoch 359/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 660us/step - loss: 0.6481 - val_loss: 0.6186\n",
      "Epoch 360/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 667us/step - loss: 0.6540 - val_loss: 0.6138\n",
      "Epoch 361/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 652us/step - loss: 0.6415 - val_loss: 0.6088\n",
      "Epoch 362/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 675us/step - loss: 0.6319 - val_loss: 0.6286\n",
      "Epoch 363/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 673us/step - loss: 0.6467 - val_loss: 0.6107\n",
      "Epoch 364/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 676us/step - loss: 0.6449 - val_loss: 0.6093\n",
      "Epoch 365/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 692us/step - loss: 0.6454 - val_loss: 0.6146\n",
      "Epoch 366/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 694us/step - loss: 0.6451 - val_loss: 0.6021\n",
      "Epoch 367/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 652us/step - loss: 0.6383 - val_loss: 0.6025\n",
      "Epoch 368/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 670us/step - loss: 0.6444 - val_loss: 0.6007\n",
      "Epoch 369/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 654us/step - loss: 0.6412 - val_loss: 0.6042\n",
      "Epoch 370/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step - loss: 0.6271 - val_loss: 0.6039\n",
      "Epoch 371/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 662us/step - loss: 0.6424 - val_loss: 0.6097\n",
      "Epoch 372/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 684us/step - loss: 0.6361 - val_loss: 0.6034\n",
      "Epoch 373/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 688us/step - loss: 0.6380 - val_loss: 0.6168\n",
      "Epoch 374/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 657us/step - loss: 0.6338 - val_loss: 0.6015\n",
      "Epoch 375/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 679us/step - loss: 0.6382 - val_loss: 0.6014\n",
      "Epoch 376/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 689us/step - loss: 0.6359 - val_loss: 0.6076\n",
      "Epoch 377/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 677us/step - loss: 0.6264 - val_loss: 0.6063\n",
      "Epoch 378/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 667us/step - loss: 0.6372 - val_loss: 0.6024\n",
      "Epoch 379/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 668us/step - loss: 0.6362 - val_loss: 0.6227\n",
      "Epoch 380/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 695us/step - loss: 0.6370 - val_loss: 0.6035\n",
      "Epoch 381/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 686us/step - loss: 0.6302 - val_loss: 0.6005\n",
      "Epoch 382/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 663us/step - loss: 0.6383 - val_loss: 0.6221\n",
      "Epoch 383/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 656us/step - loss: 0.6481 - val_loss: 0.6080\n",
      "Epoch 384/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 694us/step - loss: 0.6292 - val_loss: 0.6122\n",
      "Epoch 385/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 668us/step - loss: 0.6368 - val_loss: 0.6225\n",
      "Epoch 386/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 702us/step - loss: 0.6451 - val_loss: 0.6129\n",
      "Epoch 387/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 649us/step - loss: 0.6296 - val_loss: 0.6042\n",
      "Epoch 388/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 663us/step - loss: 0.6371 - val_loss: 0.6134\n",
      "Epoch 389/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 689us/step - loss: 0.6449 - val_loss: 0.6114\n",
      "Epoch 390/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 703us/step - loss: 0.6416 - val_loss: 0.6100\n",
      "Epoch 391/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 645us/step - loss: 0.6482 - val_loss: 0.6028\n",
      "Epoch 392/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 682us/step - loss: 0.6401 - val_loss: 0.6023\n",
      "Epoch 393/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.6388 - val_loss: 0.6041\n",
      "Epoch 394/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 675us/step - loss: 0.6444 - val_loss: 0.6057\n",
      "Epoch 395/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 692us/step - loss: 0.6330 - val_loss: 0.6036\n",
      "Epoch 396/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 679us/step - loss: 0.6334 - val_loss: 0.6164\n",
      "Epoch 397/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 670us/step - loss: 0.6386 - val_loss: 0.6110\n",
      "Epoch 398/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 673us/step - loss: 0.6382 - val_loss: 0.6209\n",
      "Epoch 399/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 695us/step - loss: 0.6419 - val_loss: 0.6031\n",
      "Epoch 400/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 674us/step - loss: 0.6336 - val_loss: 0.6014\n",
      "Epoch 401/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 673us/step - loss: 0.6373 - val_loss: 0.6061\n",
      "Epoch 402/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 694us/step - loss: 0.6365 - val_loss: 0.6015\n",
      "Epoch 403/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 707us/step - loss: 0.6394 - val_loss: 0.6066\n",
      "Epoch 404/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 731us/step - loss: 0.6409 - val_loss: 0.6249\n",
      "Epoch 405/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 669us/step - loss: 0.6416 - val_loss: 0.6024\n",
      "Epoch 406/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 684us/step - loss: 0.6465 - val_loss: 0.6030\n",
      "Epoch 407/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 711us/step - loss: 0.6420 - val_loss: 0.5996\n",
      "Epoch 408/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 674us/step - loss: 0.6418 - val_loss: 0.6073\n",
      "Epoch 409/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 701us/step - loss: 0.6386 - val_loss: 0.6041\n",
      "Epoch 410/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 734us/step - loss: 0.6216 - val_loss: 0.6079\n",
      "Epoch 411/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 667us/step - loss: 0.6347 - val_loss: 0.6073\n",
      "Epoch 412/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 649us/step - loss: 0.6381 - val_loss: 0.6044\n",
      "Epoch 413/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 697us/step - loss: 0.6450 - val_loss: 0.6057\n",
      "Epoch 414/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 709us/step - loss: 0.6363 - val_loss: 0.6050\n",
      "Epoch 415/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722us/step - loss: 0.6396 - val_loss: 0.6005\n",
      "Epoch 416/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 703us/step - loss: 0.6418 - val_loss: 0.6121\n",
      "Epoch 417/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 761us/step - loss: 0.6446 - val_loss: 0.6078\n",
      "Epoch 418/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 712us/step - loss: 0.6387 - val_loss: 0.6083\n",
      "Epoch 419/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 643us/step - loss: 0.6443 - val_loss: 0.6078\n",
      "Epoch 420/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 706us/step - loss: 0.6464 - val_loss: 0.6220\n",
      "Epoch 421/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 685us/step - loss: 0.6323 - val_loss: 0.6040\n",
      "Epoch 422/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 672us/step - loss: 0.6430 - val_loss: 0.6202\n",
      "Epoch 423/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 687us/step - loss: 0.6315 - val_loss: 0.6075\n",
      "Epoch 424/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 682us/step - loss: 0.6481 - val_loss: 0.6138\n",
      "Epoch 425/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 786us/step - loss: 0.6507 - val_loss: 0.6165\n",
      "Epoch 426/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 799us/step - loss: 0.6376 - val_loss: 0.6037\n",
      "Epoch 427/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 634us/step - loss: 0.6420 - val_loss: 0.6239\n",
      "Epoch 428/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653us/step - loss: 0.6449 - val_loss: 0.6026\n",
      "Epoch 429/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 628us/step - loss: 0.6329 - val_loss: 0.6025\n",
      "Epoch 430/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 622us/step - loss: 0.6407 - val_loss: 0.6045\n",
      "Epoch 431/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 628us/step - loss: 0.6291 - val_loss: 0.6104\n",
      "Epoch 432/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 621us/step - loss: 0.6394 - val_loss: 0.6014\n",
      "Epoch 433/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 596us/step - loss: 0.6426 - val_loss: 0.6057\n",
      "Epoch 434/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 602us/step - loss: 0.6380 - val_loss: 0.6022\n",
      "Epoch 435/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 633us/step - loss: 0.6352 - val_loss: 0.6108\n",
      "Epoch 436/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 620us/step - loss: 0.6347 - val_loss: 0.6040\n",
      "Epoch 437/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 650us/step - loss: 0.6353 - val_loss: 0.6045\n",
      "Epoch 438/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 601us/step - loss: 0.6388 - val_loss: 0.6052\n",
      "Epoch 439/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 614us/step - loss: 0.6417 - val_loss: 0.6045\n",
      "Epoch 440/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 654us/step - loss: 0.6432 - val_loss: 0.6123\n",
      "Epoch 441/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 690us/step - loss: 0.6485 - val_loss: 0.6021\n",
      "Epoch 442/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step - loss: 0.6340 - val_loss: 0.6139\n",
      "Epoch 443/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 752us/step - loss: 0.6379 - val_loss: 0.5968\n",
      "Epoch 444/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 733us/step - loss: 0.6295 - val_loss: 0.6063\n",
      "Epoch 445/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 699us/step - loss: 0.6413 - val_loss: 0.6002\n",
      "Epoch 446/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 814us/step - loss: 0.6466 - val_loss: 0.6027\n",
      "Epoch 447/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 806us/step - loss: 0.6336 - val_loss: 0.6007\n",
      "Epoch 448/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step - loss: 0.6321 - val_loss: 0.6186\n",
      "Epoch 449/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716us/step - loss: 0.6423 - val_loss: 0.6327\n",
      "Epoch 450/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 694us/step - loss: 0.6454 - val_loss: 0.5971\n",
      "Epoch 451/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 674us/step - loss: 0.6302 - val_loss: 0.6144\n",
      "Epoch 452/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step - loss: 0.6389 - val_loss: 0.6125\n",
      "Epoch 453/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 688us/step - loss: 0.6345 - val_loss: 0.6007\n",
      "Epoch 454/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 662us/step - loss: 0.6300 - val_loss: 0.6069\n",
      "Epoch 455/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 656us/step - loss: 0.6350 - val_loss: 0.6037\n",
      "Epoch 456/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671us/step - loss: 0.6391 - val_loss: 0.5997\n",
      "Epoch 457/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 655us/step - loss: 0.6313 - val_loss: 0.6048\n",
      "Epoch 458/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 657us/step - loss: 0.6382 - val_loss: 0.6297\n",
      "Epoch 459/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step - loss: 0.6369 - val_loss: 0.6055\n",
      "Epoch 460/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 677us/step - loss: 0.6317 - val_loss: 0.5993\n",
      "Epoch 461/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 658us/step - loss: 0.6479 - val_loss: 0.6054\n",
      "Epoch 462/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 656us/step - loss: 0.6421 - val_loss: 0.6072\n",
      "Epoch 463/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722us/step - loss: 0.6310 - val_loss: 0.6263\n",
      "Epoch 464/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 651us/step - loss: 0.6279 - val_loss: 0.6034\n",
      "Epoch 465/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 688us/step - loss: 0.6468 - val_loss: 0.6153\n",
      "Epoch 466/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 668us/step - loss: 0.6368 - val_loss: 0.6043\n",
      "Epoch 467/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 776us/step - loss: 0.6309 - val_loss: 0.6049\n",
      "Epoch 468/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 702us/step - loss: 0.6304 - val_loss: 0.6071\n",
      "Epoch 469/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 725us/step - loss: 0.6388 - val_loss: 0.6037\n",
      "Epoch 470/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 704us/step - loss: 0.6345 - val_loss: 0.6099\n",
      "Epoch 471/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716us/step - loss: 0.6340 - val_loss: 0.6139\n",
      "Epoch 472/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730us/step - loss: 0.6380 - val_loss: 0.6226\n",
      "Epoch 473/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 861us/step - loss: 0.6295 - val_loss: 0.6051\n",
      "Epoch 474/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 702us/step - loss: 0.6263 - val_loss: 0.6047\n",
      "Epoch 475/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 711us/step - loss: 0.6312 - val_loss: 0.6001\n",
      "Epoch 476/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 687us/step - loss: 0.6387 - val_loss: 0.5990\n",
      "Epoch 477/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 680us/step - loss: 0.6294 - val_loss: 0.6020\n",
      "Epoch 478/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 679us/step - loss: 0.6292 - val_loss: 0.6133\n",
      "Epoch 479/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 690us/step - loss: 0.6290 - val_loss: 0.6033\n",
      "Epoch 480/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 703us/step - loss: 0.6379 - val_loss: 0.6123\n",
      "Epoch 481/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722us/step - loss: 0.6355 - val_loss: 0.6158\n",
      "Epoch 482/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 673us/step - loss: 0.6346 - val_loss: 0.6319\n",
      "Epoch 483/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 686us/step - loss: 0.6329 - val_loss: 0.6048\n",
      "Epoch 484/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 676us/step - loss: 0.6329 - val_loss: 0.6234\n",
      "Epoch 485/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 672us/step - loss: 0.6352 - val_loss: 0.6025\n",
      "Epoch 486/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 693us/step - loss: 0.6313 - val_loss: 0.6071\n",
      "Epoch 487/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 684us/step - loss: 0.6359 - val_loss: 0.6048\n",
      "Epoch 488/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 673us/step - loss: 0.6396 - val_loss: 0.6064\n",
      "Epoch 489/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 660us/step - loss: 0.6315 - val_loss: 0.6057\n",
      "Epoch 490/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 657us/step - loss: 0.6366 - val_loss: 0.6158\n",
      "Epoch 491/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 658us/step - loss: 0.6386 - val_loss: 0.6050\n",
      "Epoch 492/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 642us/step - loss: 0.6146 - val_loss: 0.6087\n",
      "Epoch 493/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 686us/step - loss: 0.6342 - val_loss: 0.5996\n",
      "Epoch 494/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 696us/step - loss: 0.6379 - val_loss: 0.6101\n",
      "Epoch 495/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 774us/step - loss: 0.6323 - val_loss: 0.6052\n",
      "Epoch 496/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 782us/step - loss: 0.6390 - val_loss: 0.5979\n",
      "Epoch 497/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 692us/step - loss: 0.6404 - val_loss: 0.6098\n",
      "Epoch 498/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 654us/step - loss: 0.6375 - val_loss: 0.5975\n",
      "Epoch 499/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step - loss: 0.6344 - val_loss: 0.6050\n",
      "Epoch 500/500\n",
      "\u001b[1m3201/3201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 746us/step - loss: 0.6315 - val_loss: 0.6096\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - loss: 0.6243\n",
      "Test Loss: 0.6184812188148499\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Upper ph.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Prepare the dataset\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "ph_levels = [7 , 8 , 9 , 10]\n",
    "for ph in ph_levels:\n",
    "    ph_data = data[['Frequency', f'S11 at {ph} pH', f'S21 at {ph} pH', f'phase S11 at {ph} pH', f'phase S21 at {ph} pH']]\n",
    "    ph_data.columns = ['Frequency', 'S11', 'S21', 'phase S11', 'phase S21']\n",
    "    ph_data['pH'] = ph\n",
    "    features.append(ph_data)\n",
    "\n",
    "# Combine all features\n",
    "features = pd.concat(features, ignore_index=True)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "features[['Frequency', 'S11', 'S21', 'phase S11', 'phase S21']] = scaler.fit_transform(features[['Frequency', 'S11', 'S21', 'phase S11', 'phase S21']])\n",
    "\n",
    "# Split features and labels\n",
    "X = features[['Frequency', 'S11', 'S21', 'phase S11', 'phase S21']]\n",
    "y = features['pH']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network model with more complexity and regularization\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=8, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "[[7.5770845]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming the model is already trained and you have the data to predict\n",
    "# Prepare new data for prediction (make sure to scale it the same way as training data)\n",
    "new_data = pd.DataFrame({\n",
    "    'Frequency': [4.0166],\n",
    "    'S11': [-0.9357],\n",
    "    'S21': [-17.85208],\n",
    "    'phase S11': [-152.49893],\n",
    "    'phase S21': [0.14894]\n",
    "})\n",
    "\n",
    "# Normalize the new data\n",
    "new_data[['Frequency', 'S11', 'S21', 'phase S11', 'phase S21']] = scaler.transform(new_data[['Frequency', 'S11', 'S21', 'phase S11', 'phase S21']])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_data)\n",
    "\n",
    "# Print predictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"loss_only_8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 15:21:53.898124: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-20 15:21:53.898700: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-20 15:21:53.900743: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-20 15:21:53.907209: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-20 15:21:53.918769: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-20 15:21:53.921654: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-20 15:21:53.930745: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-20 15:21:54.478707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/tmp/ipykernel_399583/1311297590.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ph_data['pH'] = ph\n",
      "/tmp/ipykernel_399583/1311297590.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ph_data['pH'] = ph\n",
      "/tmp/ipykernel_399583/1311297590.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ph_data['pH'] = ph\n",
      "/tmp/ipykernel_399583/1311297590.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ph_data['pH'] = ph\n",
      "/home/sheesh/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-09-20 15:21:56.005153: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 79.0571 - val_loss: 57.1370\n",
      "Epoch 2/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 63.4748 - val_loss: 39.9523\n",
      "Epoch 3/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 45.9756 - val_loss: 23.5210\n",
      "Epoch 4/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 30.3968 - val_loss: 12.0053\n",
      "Epoch 5/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 18.1994 - val_loss: 5.1208\n",
      "Epoch 6/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 10.6964 - val_loss: 2.3630\n",
      "Epoch 7/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7.6353 - val_loss: 1.8904\n",
      "Epoch 8/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.4007 - val_loss: 1.8658\n",
      "Epoch 9/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.5129 - val_loss: 1.9427\n",
      "Epoch 10/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.1340 - val_loss: 1.9082\n",
      "Epoch 11/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.5658 - val_loss: 1.9309\n",
      "Epoch 12/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.3582 - val_loss: 1.9646\n",
      "Epoch 13/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.0188 - val_loss: 1.9476\n",
      "Epoch 14/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.8264 - val_loss: 1.9373\n",
      "Epoch 15/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.6943 - val_loss: 1.9025\n",
      "Epoch 16/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.5599 - val_loss: 1.9025\n",
      "Epoch 17/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.4634 - val_loss: 1.9112\n",
      "Epoch 18/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.3480 - val_loss: 1.8767\n",
      "Epoch 19/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.2498 - val_loss: 1.8566\n",
      "Epoch 20/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.1809 - val_loss: 1.8896\n",
      "Epoch 21/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.1336 - val_loss: 1.8745\n",
      "Epoch 22/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.1036 - val_loss: 1.8599\n",
      "Epoch 23/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.0226 - val_loss: 1.8241\n",
      "Epoch 24/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.0720 - val_loss: 1.8272\n",
      "Epoch 25/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.0093 - val_loss: 1.8331\n",
      "Epoch 26/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.9571 - val_loss: 1.7854\n",
      "Epoch 27/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.8970 - val_loss: 1.7804\n",
      "Epoch 28/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.8779 - val_loss: 1.7655\n",
      "Epoch 29/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.8522 - val_loss: 1.7753\n",
      "Epoch 30/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.8342 - val_loss: 1.7344\n",
      "Epoch 31/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.7993 - val_loss: 1.7554\n",
      "Epoch 32/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.7824 - val_loss: 1.7436\n",
      "Epoch 33/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.7917 - val_loss: 1.7333\n",
      "Epoch 34/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.7574 - val_loss: 1.7299\n",
      "Epoch 35/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.7014 - val_loss: 1.7079\n",
      "Epoch 36/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.6975 - val_loss: 1.7093\n",
      "Epoch 37/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.6966 - val_loss: 1.6885\n",
      "Epoch 38/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.6449 - val_loss: 1.6786\n",
      "Epoch 39/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.6827 - val_loss: 1.6686\n",
      "Epoch 40/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.6240 - val_loss: 1.6669\n",
      "Epoch 41/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.6411 - val_loss: 1.6505\n",
      "Epoch 42/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.5891 - val_loss: 1.6395\n",
      "Epoch 43/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.5992 - val_loss: 1.6470\n",
      "Epoch 44/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.5913 - val_loss: 1.6557\n",
      "Epoch 45/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.5846 - val_loss: 1.6336\n",
      "Epoch 46/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.5727 - val_loss: 1.6361\n",
      "Epoch 47/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.5040 - val_loss: 1.6127\n",
      "Epoch 48/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.5366 - val_loss: 1.6070\n",
      "Epoch 49/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.5181 - val_loss: 1.6056\n",
      "Epoch 50/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.5077 - val_loss: 1.6126\n",
      "Epoch 51/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.5012 - val_loss: 1.6027\n",
      "Epoch 52/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.4747 - val_loss: 1.5989\n",
      "Epoch 53/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.4692 - val_loss: 1.5896\n",
      "Epoch 54/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.4361 - val_loss: 1.5860\n",
      "Epoch 55/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.4432 - val_loss: 1.5893\n",
      "Epoch 56/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.4289 - val_loss: 1.5832\n",
      "Epoch 57/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.3590 - val_loss: 1.5826\n",
      "Epoch 58/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.3927 - val_loss: 1.5856\n",
      "Epoch 59/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.3428 - val_loss: 1.5724\n",
      "Epoch 60/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.3675 - val_loss: 1.5581\n",
      "Epoch 61/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.3732 - val_loss: 1.5803\n",
      "Epoch 62/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.3755 - val_loss: 1.5748\n",
      "Epoch 63/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.3766 - val_loss: 1.5574\n",
      "Epoch 64/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.3610 - val_loss: 1.5519\n",
      "Epoch 65/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.3731 - val_loss: 1.5449\n",
      "Epoch 66/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.3177 - val_loss: 1.5556\n",
      "Epoch 67/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.3218 - val_loss: 1.5479\n",
      "Epoch 68/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.2921 - val_loss: 1.5409\n",
      "Epoch 69/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.2985 - val_loss: 1.5512\n",
      "Epoch 70/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.3006 - val_loss: 1.5263\n",
      "Epoch 71/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.3133 - val_loss: 1.5237\n",
      "Epoch 72/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.2616 - val_loss: 1.5288\n",
      "Epoch 73/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.2840 - val_loss: 1.5177\n",
      "Epoch 74/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.2402 - val_loss: 1.5244\n",
      "Epoch 75/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.2727 - val_loss: 1.5170\n",
      "Epoch 76/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.2115 - val_loss: 1.5127\n",
      "Epoch 77/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.2219 - val_loss: 1.5071\n",
      "Epoch 78/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.1752 - val_loss: 1.5119\n",
      "Epoch 79/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.1894 - val_loss: 1.5025\n",
      "Epoch 80/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.2311 - val_loss: 1.5054\n",
      "Epoch 81/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.2031 - val_loss: 1.4928\n",
      "Epoch 82/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.2122 - val_loss: 1.4788\n",
      "Epoch 83/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.1704 - val_loss: 1.4938\n",
      "Epoch 84/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.1777 - val_loss: 1.4646\n",
      "Epoch 85/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.1358 - val_loss: 1.4714\n",
      "Epoch 86/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.1769 - val_loss: 1.4792\n",
      "Epoch 87/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.1750 - val_loss: 1.4627\n",
      "Epoch 88/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.1462 - val_loss: 1.4750\n",
      "Epoch 89/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.1206 - val_loss: 1.4605\n",
      "Epoch 90/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.1570 - val_loss: 1.4780\n",
      "Epoch 91/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.1466 - val_loss: 1.4643\n",
      "Epoch 92/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.1082 - val_loss: 1.4629\n",
      "Epoch 93/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0969 - val_loss: 1.4625\n",
      "Epoch 94/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.1064 - val_loss: 1.4668\n",
      "Epoch 95/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0946 - val_loss: 1.4441\n",
      "Epoch 96/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.1132 - val_loss: 1.4343\n",
      "Epoch 97/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0764 - val_loss: 1.4446\n",
      "Epoch 98/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0623 - val_loss: 1.4354\n",
      "Epoch 99/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0707 - val_loss: 1.4405\n",
      "Epoch 100/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0964 - val_loss: 1.4366\n",
      "Epoch 101/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0533 - val_loss: 1.4274\n",
      "Epoch 102/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0408 - val_loss: 1.4348\n",
      "Epoch 103/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0181 - val_loss: 1.4286\n",
      "Epoch 104/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0346 - val_loss: 1.4205\n",
      "Epoch 105/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0239 - val_loss: 1.4236\n",
      "Epoch 106/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0489 - val_loss: 1.4320\n",
      "Epoch 107/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0320 - val_loss: 1.4193\n",
      "Epoch 108/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0452 - val_loss: 1.4105\n",
      "Epoch 109/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0327 - val_loss: 1.4242\n",
      "Epoch 110/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9829 - val_loss: 1.4104\n",
      "Epoch 111/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9986 - val_loss: 1.4142\n",
      "Epoch 112/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.0063 - val_loss: 1.3966\n",
      "Epoch 113/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9865 - val_loss: 1.3965\n",
      "Epoch 114/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9581 - val_loss: 1.4044\n",
      "Epoch 115/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9635 - val_loss: 1.4084\n",
      "Epoch 116/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9477 - val_loss: 1.4012\n",
      "Epoch 117/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9755 - val_loss: 1.3988\n",
      "Epoch 118/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9532 - val_loss: 1.3778\n",
      "Epoch 119/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9409 - val_loss: 1.3934\n",
      "Epoch 120/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9436 - val_loss: 1.3754\n",
      "Epoch 121/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9320 - val_loss: 1.3785\n",
      "Epoch 122/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9236 - val_loss: 1.3733\n",
      "Epoch 123/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9010 - val_loss: 1.3734\n",
      "Epoch 124/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9311 - val_loss: 1.3657\n",
      "Epoch 125/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9305 - val_loss: 1.3616\n",
      "Epoch 126/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9091 - val_loss: 1.3660\n",
      "Epoch 127/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8966 - val_loss: 1.3807\n",
      "Epoch 128/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.9007 - val_loss: 1.3491\n",
      "Epoch 129/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8966 - val_loss: 1.3584\n",
      "Epoch 130/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8854 - val_loss: 1.3428\n",
      "Epoch 131/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8748 - val_loss: 1.3471\n",
      "Epoch 132/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8878 - val_loss: 1.3453\n",
      "Epoch 133/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8857 - val_loss: 1.3432\n",
      "Epoch 134/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8583 - val_loss: 1.3416\n",
      "Epoch 135/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8754 - val_loss: 1.3546\n",
      "Epoch 136/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8511 - val_loss: 1.3391\n",
      "Epoch 137/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8753 - val_loss: 1.3313\n",
      "Epoch 138/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8346 - val_loss: 1.3312\n",
      "Epoch 139/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8434 - val_loss: 1.3267\n",
      "Epoch 140/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8444 - val_loss: 1.3235\n",
      "Epoch 141/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8159 - val_loss: 1.3255\n",
      "Epoch 142/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8226 - val_loss: 1.3194\n",
      "Epoch 143/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8125 - val_loss: 1.3202\n",
      "Epoch 144/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8364 - val_loss: 1.3174\n",
      "Epoch 145/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8249 - val_loss: 1.3118\n",
      "Epoch 146/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8064 - val_loss: 1.3057\n",
      "Epoch 147/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7887 - val_loss: 1.3090\n",
      "Epoch 148/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7735 - val_loss: 1.3009\n",
      "Epoch 149/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8093 - val_loss: 1.2971\n",
      "Epoch 150/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7701 - val_loss: 1.3010\n",
      "Epoch 151/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7742 - val_loss: 1.2944\n",
      "Epoch 152/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7599 - val_loss: 1.2924\n",
      "Epoch 153/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7698 - val_loss: 1.2965\n",
      "Epoch 154/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7546 - val_loss: 1.2887\n",
      "Epoch 155/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7702 - val_loss: 1.2871\n",
      "Epoch 156/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7278 - val_loss: 1.2774\n",
      "Epoch 157/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7630 - val_loss: 1.2755\n",
      "Epoch 158/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7310 - val_loss: 1.2687\n",
      "Epoch 159/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7294 - val_loss: 1.2769\n",
      "Epoch 160/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7365 - val_loss: 1.2636\n",
      "Epoch 161/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7336 - val_loss: 1.2628\n",
      "Epoch 162/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7422 - val_loss: 1.2724\n",
      "Epoch 163/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7107 - val_loss: 1.2678\n",
      "Epoch 164/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7004 - val_loss: 1.2664\n",
      "Epoch 165/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7130 - val_loss: 1.2614\n",
      "Epoch 166/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7201 - val_loss: 1.2651\n",
      "Epoch 167/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6876 - val_loss: 1.2559\n",
      "Epoch 168/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7056 - val_loss: 1.2570\n",
      "Epoch 169/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6788 - val_loss: 1.2502\n",
      "Epoch 170/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6920 - val_loss: 1.2536\n",
      "Epoch 171/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7014 - val_loss: 1.2516\n",
      "Epoch 172/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6904 - val_loss: 1.2433\n",
      "Epoch 173/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6653 - val_loss: 1.2482\n",
      "Epoch 174/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6711 - val_loss: 1.2469\n",
      "Epoch 175/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6745 - val_loss: 1.2384\n",
      "Epoch 176/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6427 - val_loss: 1.2369\n",
      "Epoch 177/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6464 - val_loss: 1.2362\n",
      "Epoch 178/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6354 - val_loss: 1.2335\n",
      "Epoch 179/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6350 - val_loss: 1.2284\n",
      "Epoch 180/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6561 - val_loss: 1.2318\n",
      "Epoch 181/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6594 - val_loss: 1.2271\n",
      "Epoch 182/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6415 - val_loss: 1.2168\n",
      "Epoch 183/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6359 - val_loss: 1.2173\n",
      "Epoch 184/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6433 - val_loss: 1.2078\n",
      "Epoch 185/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6353 - val_loss: 1.2075\n",
      "Epoch 186/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6434 - val_loss: 1.2116\n",
      "Epoch 187/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6087 - val_loss: 1.2158\n",
      "Epoch 188/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6058 - val_loss: 1.1945\n",
      "Epoch 189/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5826 - val_loss: 1.2041\n",
      "Epoch 190/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5977 - val_loss: 1.1966\n",
      "Epoch 191/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6059 - val_loss: 1.1899\n",
      "Epoch 192/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.6006 - val_loss: 1.1881\n",
      "Epoch 193/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5917 - val_loss: 1.1927\n",
      "Epoch 194/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5724 - val_loss: 1.1842\n",
      "Epoch 195/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5845 - val_loss: 1.1807\n",
      "Epoch 196/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5921 - val_loss: 1.1817\n",
      "Epoch 197/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5818 - val_loss: 1.1791\n",
      "Epoch 198/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5701 - val_loss: 1.1930\n",
      "Epoch 199/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5749 - val_loss: 1.1730\n",
      "Epoch 200/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5692 - val_loss: 1.1755\n",
      "Epoch 201/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5448 - val_loss: 1.1689\n",
      "Epoch 202/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5583 - val_loss: 1.1708\n",
      "Epoch 203/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5324 - val_loss: 1.1632\n",
      "Epoch 204/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5632 - val_loss: 1.1685\n",
      "Epoch 205/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5372 - val_loss: 1.1688\n",
      "Epoch 206/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5379 - val_loss: 1.1554\n",
      "Epoch 207/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5123 - val_loss: 1.1629\n",
      "Epoch 208/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5240 - val_loss: 1.1721\n",
      "Epoch 209/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5361 - val_loss: 1.1658\n",
      "Epoch 210/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5179 - val_loss: 1.1661\n",
      "Epoch 211/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5037 - val_loss: 1.1527\n",
      "Epoch 212/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5202 - val_loss: 1.1525\n",
      "Epoch 213/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4875 - val_loss: 1.1515\n",
      "Epoch 214/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5110 - val_loss: 1.1517\n",
      "Epoch 215/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.5065 - val_loss: 1.1484\n",
      "Epoch 216/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4859 - val_loss: 1.1423\n",
      "Epoch 217/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4902 - val_loss: 1.1412\n",
      "Epoch 218/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4774 - val_loss: 1.1351\n",
      "Epoch 219/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4856 - val_loss: 1.1287\n",
      "Epoch 220/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4782 - val_loss: 1.1331\n",
      "Epoch 221/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4636 - val_loss: 1.1266\n",
      "Epoch 222/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4693 - val_loss: 1.1343\n",
      "Epoch 223/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4724 - val_loss: 1.1244\n",
      "Epoch 224/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4531 - val_loss: 1.1238\n",
      "Epoch 225/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4726 - val_loss: 1.1203\n",
      "Epoch 226/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4591 - val_loss: 1.1210\n",
      "Epoch 227/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4196 - val_loss: 1.1132\n",
      "Epoch 228/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4504 - val_loss: 1.1148\n",
      "Epoch 229/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.4542 - val_loss: 1.1235\n",
      "Epoch 230/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.4495 - val_loss: 1.1118\n",
      "Epoch 231/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.4381 - val_loss: 1.1084\n",
      "Epoch 232/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.4347 - val_loss: 1.1116\n",
      "Epoch 233/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.4414 - val_loss: 1.1029\n",
      "Epoch 234/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.4322 - val_loss: 1.1149\n",
      "Epoch 235/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.3996 - val_loss: 1.1044\n",
      "Epoch 236/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.4144 - val_loss: 1.1026\n",
      "Epoch 237/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.4068 - val_loss: 1.1119\n",
      "Epoch 238/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.3928 - val_loss: 1.0999\n",
      "Epoch 239/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.4155 - val_loss: 1.0931\n",
      "Epoch 240/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.4083 - val_loss: 1.0933\n",
      "Epoch 241/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.4025 - val_loss: 1.0953\n",
      "Epoch 242/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.4133 - val_loss: 1.0938\n",
      "Epoch 243/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.4127 - val_loss: 1.0830\n",
      "Epoch 244/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.3957 - val_loss: 1.0874\n",
      "Epoch 245/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.3988 - val_loss: 1.0935\n",
      "Epoch 246/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.4004 - val_loss: 1.0901\n",
      "Epoch 247/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.3914 - val_loss: 1.0815\n",
      "Epoch 248/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3922 - val_loss: 1.0933\n",
      "Epoch 249/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3673 - val_loss: 1.0888\n",
      "Epoch 250/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3751 - val_loss: 1.0880\n",
      "Epoch 251/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3528 - val_loss: 1.0872\n",
      "Epoch 252/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3813 - val_loss: 1.0790\n",
      "Epoch 253/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3570 - val_loss: 1.0873\n",
      "Epoch 254/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3551 - val_loss: 1.0824\n",
      "Epoch 255/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3496 - val_loss: 1.0756\n",
      "Epoch 256/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3427 - val_loss: 1.0772\n",
      "Epoch 257/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3685 - val_loss: 1.0681\n",
      "Epoch 258/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3445 - val_loss: 1.0797\n",
      "Epoch 259/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3657 - val_loss: 1.0732\n",
      "Epoch 260/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.3437 - val_loss: 1.0670\n",
      "Epoch 261/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.3508 - val_loss: 1.0601\n",
      "Epoch 262/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3357 - val_loss: 1.0621\n",
      "Epoch 263/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3267 - val_loss: 1.0599\n",
      "Epoch 264/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3507 - val_loss: 1.0671\n",
      "Epoch 265/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3289 - val_loss: 1.0657\n",
      "Epoch 266/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3144 - val_loss: 1.0571\n",
      "Epoch 267/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3528 - val_loss: 1.0602\n",
      "Epoch 268/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3284 - val_loss: 1.0648\n",
      "Epoch 269/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3147 - val_loss: 1.0600\n",
      "Epoch 270/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3219 - val_loss: 1.0574\n",
      "Epoch 271/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2989 - val_loss: 1.0463\n",
      "Epoch 272/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3158 - val_loss: 1.0492\n",
      "Epoch 273/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2958 - val_loss: 1.0488\n",
      "Epoch 274/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3048 - val_loss: 1.0486\n",
      "Epoch 275/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3113 - val_loss: 1.0534\n",
      "Epoch 276/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2988 - val_loss: 1.0444\n",
      "Epoch 277/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 1.2814 - val_loss: 1.0428\n",
      "Epoch 278/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2813 - val_loss: 1.0346\n",
      "Epoch 279/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2988 - val_loss: 1.0432\n",
      "Epoch 280/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3055 - val_loss: 1.0383\n",
      "Epoch 281/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2820 - val_loss: 1.0302\n",
      "Epoch 282/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1.2844 - val_loss: 1.0345\n",
      "Epoch 283/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2629 - val_loss: 1.0348\n",
      "Epoch 284/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2720 - val_loss: 1.0307\n",
      "Epoch 285/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2646 - val_loss: 1.0309\n",
      "Epoch 286/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2654 - val_loss: 1.0260\n",
      "Epoch 287/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2692 - val_loss: 1.0352\n",
      "Epoch 288/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2700 - val_loss: 1.0307\n",
      "Epoch 289/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2687 - val_loss: 1.0260\n",
      "Epoch 290/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2567 - val_loss: 1.0207\n",
      "Epoch 291/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2573 - val_loss: 1.0297\n",
      "Epoch 292/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2679 - val_loss: 1.0247\n",
      "Epoch 293/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2576 - val_loss: 1.0168\n",
      "Epoch 294/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2578 - val_loss: 1.0072\n",
      "Epoch 295/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2411 - val_loss: 1.0091\n",
      "Epoch 296/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2534 - val_loss: 1.0123\n",
      "Epoch 297/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2367 - val_loss: 1.0208\n",
      "Epoch 298/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2460 - val_loss: 1.0145\n",
      "Epoch 299/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2334 - val_loss: 1.0095\n",
      "Epoch 300/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2398 - val_loss: 1.0071\n",
      "Epoch 301/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2237 - val_loss: 1.0058\n",
      "Epoch 302/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2141 - val_loss: 1.0131\n",
      "Epoch 303/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2203 - val_loss: 1.0196\n",
      "Epoch 304/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2026 - val_loss: 1.0060\n",
      "Epoch 305/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2174 - val_loss: 1.0068\n",
      "Epoch 306/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2127 - val_loss: 1.0049\n",
      "Epoch 307/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2138 - val_loss: 0.9996\n",
      "Epoch 308/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2122 - val_loss: 1.0000\n",
      "Epoch 309/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2061 - val_loss: 1.0027\n",
      "Epoch 310/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2165 - val_loss: 0.9972\n",
      "Epoch 311/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2000 - val_loss: 0.9981\n",
      "Epoch 312/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2226 - val_loss: 0.9908\n",
      "Epoch 313/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2032 - val_loss: 0.9953\n",
      "Epoch 314/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1918 - val_loss: 0.9865\n",
      "Epoch 315/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2057 - val_loss: 0.9843\n",
      "Epoch 316/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1989 - val_loss: 0.9942\n",
      "Epoch 317/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1895 - val_loss: 0.9803\n",
      "Epoch 318/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1876 - val_loss: 0.9792\n",
      "Epoch 319/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2083 - val_loss: 0.9799\n",
      "Epoch 320/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2083 - val_loss: 0.9886\n",
      "Epoch 321/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.2000 - val_loss: 0.9789\n",
      "Epoch 322/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1801 - val_loss: 0.9767\n",
      "Epoch 323/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1793 - val_loss: 0.9752\n",
      "Epoch 324/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1819 - val_loss: 0.9757\n",
      "Epoch 325/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1856 - val_loss: 0.9676\n",
      "Epoch 326/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1803 - val_loss: 0.9744\n",
      "Epoch 327/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1547 - val_loss: 0.9670\n",
      "Epoch 328/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1764 - val_loss: 0.9690\n",
      "Epoch 329/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1719 - val_loss: 0.9642\n",
      "Epoch 330/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1648 - val_loss: 0.9728\n",
      "Epoch 331/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1762 - val_loss: 0.9658\n",
      "Epoch 332/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1605 - val_loss: 0.9626\n",
      "Epoch 333/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1420 - val_loss: 0.9731\n",
      "Epoch 334/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1508 - val_loss: 0.9612\n",
      "Epoch 335/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1593 - val_loss: 0.9597\n",
      "Epoch 336/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1579 - val_loss: 0.9646\n",
      "Epoch 337/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1651 - val_loss: 0.9547\n",
      "Epoch 338/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1604 - val_loss: 0.9514\n",
      "Epoch 339/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1416 - val_loss: 0.9536\n",
      "Epoch 340/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1431 - val_loss: 0.9514\n",
      "Epoch 341/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1467 - val_loss: 0.9526\n",
      "Epoch 342/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1349 - val_loss: 0.9471\n",
      "Epoch 343/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1347 - val_loss: 0.9483\n",
      "Epoch 344/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1341 - val_loss: 0.9427\n",
      "Epoch 345/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1535 - val_loss: 0.9437\n",
      "Epoch 346/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1228 - val_loss: 0.9411\n",
      "Epoch 347/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1226 - val_loss: 0.9369\n",
      "Epoch 348/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1309 - val_loss: 0.9404\n",
      "Epoch 349/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1266 - val_loss: 0.9370\n",
      "Epoch 350/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1137 - val_loss: 0.9346\n",
      "Epoch 351/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1180 - val_loss: 0.9385\n",
      "Epoch 352/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1341 - val_loss: 0.9371\n",
      "Epoch 353/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1146 - val_loss: 0.9344\n",
      "Epoch 354/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1426 - val_loss: 0.9322\n",
      "Epoch 355/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1137 - val_loss: 0.9260\n",
      "Epoch 356/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1063 - val_loss: 0.9305\n",
      "Epoch 357/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1115 - val_loss: 0.9232\n",
      "Epoch 358/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1168 - val_loss: 0.9280\n",
      "Epoch 359/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1097 - val_loss: 0.9198\n",
      "Epoch 360/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1005 - val_loss: 0.9262\n",
      "Epoch 361/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1070 - val_loss: 0.9227\n",
      "Epoch 362/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1154 - val_loss: 0.9188\n",
      "Epoch 363/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1096 - val_loss: 0.9208\n",
      "Epoch 364/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0989 - val_loss: 0.9165\n",
      "Epoch 365/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1064 - val_loss: 0.9228\n",
      "Epoch 366/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0983 - val_loss: 0.9164\n",
      "Epoch 367/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0962 - val_loss: 0.9139\n",
      "Epoch 368/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0887 - val_loss: 0.9101\n",
      "Epoch 369/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0916 - val_loss: 0.9165\n",
      "Epoch 370/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0773 - val_loss: 0.9128\n",
      "Epoch 371/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0929 - val_loss: 0.9120\n",
      "Epoch 372/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0815 - val_loss: 0.9131\n",
      "Epoch 373/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0833 - val_loss: 0.9026\n",
      "Epoch 374/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0917 - val_loss: 0.9071\n",
      "Epoch 375/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0759 - val_loss: 0.9063\n",
      "Epoch 376/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0751 - val_loss: 0.9008\n",
      "Epoch 377/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0805 - val_loss: 0.9058\n",
      "Epoch 378/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0776 - val_loss: 0.9070\n",
      "Epoch 379/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0723 - val_loss: 0.9023\n",
      "Epoch 380/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0584 - val_loss: 0.8998\n",
      "Epoch 381/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0730 - val_loss: 0.9001\n",
      "Epoch 382/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0732 - val_loss: 0.8958\n",
      "Epoch 383/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0619 - val_loss: 0.8993\n",
      "Epoch 384/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0626 - val_loss: 0.8981\n",
      "Epoch 385/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0663 - val_loss: 0.8960\n",
      "Epoch 386/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0737 - val_loss: 0.8921\n",
      "Epoch 387/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0534 - val_loss: 0.8912\n",
      "Epoch 388/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0601 - val_loss: 0.8903\n",
      "Epoch 389/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0508 - val_loss: 0.8870\n",
      "Epoch 390/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0588 - val_loss: 0.8880\n",
      "Epoch 391/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0539 - val_loss: 0.8794\n",
      "Epoch 392/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0397 - val_loss: 0.8813\n",
      "Epoch 393/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0554 - val_loss: 0.8795\n",
      "Epoch 394/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0517 - val_loss: 0.8840\n",
      "Epoch 395/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0619 - val_loss: 0.8763\n",
      "Epoch 396/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0652 - val_loss: 0.8737\n",
      "Epoch 397/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0484 - val_loss: 0.8757\n",
      "Epoch 398/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0397 - val_loss: 0.8822\n",
      "Epoch 399/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0477 - val_loss: 0.8727\n",
      "Epoch 400/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0352 - val_loss: 0.8731\n",
      "Epoch 401/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0446 - val_loss: 0.8724\n",
      "Epoch 402/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0488 - val_loss: 0.8678\n",
      "Epoch 403/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0358 - val_loss: 0.8712\n",
      "Epoch 404/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0231 - val_loss: 0.8700\n",
      "Epoch 405/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0492 - val_loss: 0.8679\n",
      "Epoch 406/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0361 - val_loss: 0.8697\n",
      "Epoch 407/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0330 - val_loss: 0.8628\n",
      "Epoch 408/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0285 - val_loss: 0.8651\n",
      "Epoch 409/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0262 - val_loss: 0.8604\n",
      "Epoch 410/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0239 - val_loss: 0.8587\n",
      "Epoch 411/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0112 - val_loss: 0.8622\n",
      "Epoch 412/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0278 - val_loss: 0.8603\n",
      "Epoch 413/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0195 - val_loss: 0.8568\n",
      "Epoch 414/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0352 - val_loss: 0.8571\n",
      "Epoch 415/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0241 - val_loss: 0.8548\n",
      "Epoch 416/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0145 - val_loss: 0.8559\n",
      "Epoch 417/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0145 - val_loss: 0.8543\n",
      "Epoch 418/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0207 - val_loss: 0.8551\n",
      "Epoch 419/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0067 - val_loss: 0.8481\n",
      "Epoch 420/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0072 - val_loss: 0.8452\n",
      "Epoch 421/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0065 - val_loss: 0.8476\n",
      "Epoch 422/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0045 - val_loss: 0.8437\n",
      "Epoch 423/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9946 - val_loss: 0.8401\n",
      "Epoch 424/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0084 - val_loss: 0.8448\n",
      "Epoch 425/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0083 - val_loss: 0.8410\n",
      "Epoch 426/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0018 - val_loss: 0.8463\n",
      "Epoch 427/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9929 - val_loss: 0.8372\n",
      "Epoch 428/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0013 - val_loss: 0.8377\n",
      "Epoch 429/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9998 - val_loss: 0.8321\n",
      "Epoch 430/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9900 - val_loss: 0.8362\n",
      "Epoch 431/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0011 - val_loss: 0.8340\n",
      "Epoch 432/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9992 - val_loss: 0.8330\n",
      "Epoch 433/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9956 - val_loss: 0.8359\n",
      "Epoch 434/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9814 - val_loss: 0.8286\n",
      "Epoch 435/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9879 - val_loss: 0.8348\n",
      "Epoch 436/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9872 - val_loss: 0.8264\n",
      "Epoch 437/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9907 - val_loss: 0.8338\n",
      "Epoch 438/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9921 - val_loss: 0.8264\n",
      "Epoch 439/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9825 - val_loss: 0.8265\n",
      "Epoch 440/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9847 - val_loss: 0.8306\n",
      "Epoch 441/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9923 - val_loss: 0.8246\n",
      "Epoch 442/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9865 - val_loss: 0.8210\n",
      "Epoch 443/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9669 - val_loss: 0.8245\n",
      "Epoch 444/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9816 - val_loss: 0.8215\n",
      "Epoch 445/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9855 - val_loss: 0.8217\n",
      "Epoch 446/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9712 - val_loss: 0.8222\n",
      "Epoch 447/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9853 - val_loss: 0.8186\n",
      "Epoch 448/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9743 - val_loss: 0.8149\n",
      "Epoch 449/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9775 - val_loss: 0.8212\n",
      "Epoch 450/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9605 - val_loss: 0.8180\n",
      "Epoch 451/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9717 - val_loss: 0.8196\n",
      "Epoch 452/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9705 - val_loss: 0.8162\n",
      "Epoch 453/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9759 - val_loss: 0.8088\n",
      "Epoch 454/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9778 - val_loss: 0.8123\n",
      "Epoch 455/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9706 - val_loss: 0.8144\n",
      "Epoch 456/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9565 - val_loss: 0.8067\n",
      "Epoch 457/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9786 - val_loss: 0.8142\n",
      "Epoch 458/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9709 - val_loss: 0.8040\n",
      "Epoch 459/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9752 - val_loss: 0.8071\n",
      "Epoch 460/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9610 - val_loss: 0.8042\n",
      "Epoch 461/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9672 - val_loss: 0.8015\n",
      "Epoch 462/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9609 - val_loss: 0.8009\n",
      "Epoch 463/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9615 - val_loss: 0.8084\n",
      "Epoch 464/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9498 - val_loss: 0.8021\n",
      "Epoch 465/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9576 - val_loss: 0.7965\n",
      "Epoch 466/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9646 - val_loss: 0.7957\n",
      "Epoch 467/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9515 - val_loss: 0.8024\n",
      "Epoch 468/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9548 - val_loss: 0.7911\n",
      "Epoch 469/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9550 - val_loss: 0.7993\n",
      "Epoch 470/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9568 - val_loss: 0.7913\n",
      "Epoch 471/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9466 - val_loss: 0.7925\n",
      "Epoch 472/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9374 - val_loss: 0.7852\n",
      "Epoch 473/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9554 - val_loss: 0.7907\n",
      "Epoch 474/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9369 - val_loss: 0.7953\n",
      "Epoch 475/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9487 - val_loss: 0.7891\n",
      "Epoch 476/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9277 - val_loss: 0.7939\n",
      "Epoch 477/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9450 - val_loss: 0.7907\n",
      "Epoch 478/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9383 - val_loss: 0.7863\n",
      "Epoch 479/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9370 - val_loss: 0.7873\n",
      "Epoch 480/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9338 - val_loss: 0.7839\n",
      "Epoch 481/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9387 - val_loss: 0.7802\n",
      "Epoch 482/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9390 - val_loss: 0.7834\n",
      "Epoch 483/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9340 - val_loss: 0.7890\n",
      "Epoch 484/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9312 - val_loss: 0.7770\n",
      "Epoch 485/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9486 - val_loss: 0.7751\n",
      "Epoch 486/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9328 - val_loss: 0.7734\n",
      "Epoch 487/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9239 - val_loss: 0.7807\n",
      "Epoch 488/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9220 - val_loss: 0.7805\n",
      "Epoch 489/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9223 - val_loss: 0.7693\n",
      "Epoch 490/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9320 - val_loss: 0.7712\n",
      "Epoch 491/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9203 - val_loss: 0.7764\n",
      "Epoch 492/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9349 - val_loss: 0.7730\n",
      "Epoch 493/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9281 - val_loss: 0.7693\n",
      "Epoch 494/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9149 - val_loss: 0.7710\n",
      "Epoch 495/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9125 - val_loss: 0.7782\n",
      "Epoch 496/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9237 - val_loss: 0.7724\n",
      "Epoch 497/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9275 - val_loss: 0.7720\n",
      "Epoch 498/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9276 - val_loss: 0.7662\n",
      "Epoch 499/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9053 - val_loss: 0.7642\n",
      "Epoch 500/500\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9164 - val_loss: 0.7656\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 0.7902\n",
      "Test Loss: 0.7864197492599487\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n",
      "R² Score (Test Set): 0.4759\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom R² metric\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# def r2_keras(y_true, y_pred):\n",
    "#     y_true = K.cast(y_true, 'float32')  # Ensure y_true is float32\n",
    "#     SS_res = K.sum(K.square(y_true - y_pred))  # Residual sum of squares\n",
    "#     SS_tot = K.sum(K.square(y_true - K.mean(y_true)))  # Total sum of squares\n",
    "#     return (1 - SS_res / (SS_tot + K.epsilon()))\n",
    "\n",
    "# Load the dataset (same as before)\n",
    "file_path = '../Upper ph.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Prepare the dataset (same as before)\n",
    "features = []\n",
    "ph_levels = [7 , 8 , 9 , 10]\n",
    "for ph in ph_levels:\n",
    "    ph_data = data[['Frequency', f'S11 at {ph} pH', f'S21 at {ph} pH', f'phase S11 at {ph} pH', f'phase S21 at {ph} pH']]\n",
    "    ph_data.columns = ['Frequency', 'S11', 'S21', 'phase S11', 'phase S21']\n",
    "    ph_data['pH'] = ph\n",
    "    features.append(ph_data)\n",
    "\n",
    "# Combine all features\n",
    "features = pd.concat(features, ignore_index=True)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "features[['Frequency', 'S11', 'S21', 'phase S11', 'phase S21']] = scaler.fit_transform(features[['Frequency', 'S11', 'S21', 'phase S11', 'phase S21']])\n",
    "\n",
    "# Split features and labels\n",
    "X = features[['Frequency', 'S11', 'S21', 'phase S11', 'phase S21']]\n",
    "y = features['pH']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a more powerful neural network\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers with Batch Normalization and Dropout\n",
    "model.add(Dense(512, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.00001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=16, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R² Score for the test data\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R² Score (Test Set): {r2:.4f}')\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "[[7.5497007]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming the model is already trained and you have the data to predict\n",
    "# Prepare new data for prediction (make sure to scale it the same way as training data)\n",
    "new_data = pd.DataFrame({\n",
    "    'Frequency': [4.0166],\n",
    "    'S11': [-0.9357],\n",
    "    'S21': [-17.85208],\n",
    "    'phase S11': [-152.49893],\n",
    "    'phase S21': [0.14894]\n",
    "})\n",
    "\n",
    "# Normalize the new data\n",
    "new_data[['Frequency', 'S11', 'S21', 'phase S11', 'phase S21']] = scaler.transform(new_data[['Frequency', 'S11', 'S21', 'phase S11', 'phase S21']])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_data)\n",
    "\n",
    "# Print predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
